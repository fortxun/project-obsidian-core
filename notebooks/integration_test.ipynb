{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b3e8ce0",
   "metadata": {},
   "source": [
    "# Project Obsidian Core - Integration Test Notebook\n",
    "\n",
    "This notebook verifies end-to-end data flow from databases through OpenTelemetry QAN processors to Druid and finally to Jupyter analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d89b3d",
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# Configure matplotlib\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d5c92a",
   "metadata": {},
   "source": [
    "## Step 1: Verify Druid Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f42b30",
   "metadata": {},
   "source": [
    "# Druid configuration\n",
    "DRUID_HOST = 'druid-router'\n",
    "DRUID_PORT = 8888\n",
    "DRUID_URL = f'http://{DRUID_HOST}:{DRUID_PORT}'\n",
    "\n",
    "# Helper function to execute Druid SQL queries\n",
    "def query_druid(sql):\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f'{DRUID_URL}/druid/v2/sql',\n",
    "            headers={'Content-Type': 'application/json'},\n",
    "            json={'query': sql, 'context': {'sqlQueryId': f'test-{int(time.time())}'}}\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Exception: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test connection and list available tables\n",
    "tables = query_druid(\"SHOW TABLES\")\n",
    "if tables:\n",
    "    print(\"Successfully connected to Druid\")\n",
    "    print(f\"Available tables: {tables}\")\n",
    "else:\n",
    "    print(\"Failed to connect to Druid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5e7bf9",
   "metadata": {},
   "source": [
    "## Step 2: Check QAN Data Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1da75f",
   "metadata": {},
   "source": [
    "# Define time range for analysis (last hour by default)\n",
    "end_time = datetime.now()\n",
    "start_time = end_time - timedelta(hours=1)\n",
    "\n",
    "# Format for Druid SQL\n",
    "start_time_str = start_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "end_time_str = end_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "print(f\"Analyzing data from {start_time_str} to {end_time_str}\")\n",
    "\n",
    "# Query for QAN data counts by database system\n",
    "count_query = f\"\"\"\n",
    "SELECT\n",
    "  db.system AS database_system,\n",
    "  COUNT(*) AS record_count\n",
    "FROM qan_db\n",
    "WHERE \"__time\" BETWEEN TIMESTAMP '{start_time_str}' AND TIMESTAMP '{end_time_str}'\n",
    "GROUP BY db.system\n",
    "\"\"\"\n",
    "\n",
    "count_results = query_druid(count_query)\n",
    "if count_results:\n",
    "    df_counts = pd.DataFrame(count_results)\n",
    "    print(\"QAN Data Records:\")\n",
    "    display(df_counts)\n",
    "    \n",
    "    # Check if we have data for both systems\n",
    "    systems = set(df_counts['database_system'])\n",
    "    if 'mysql' in systems and 'postgresql' in systems:\n",
    "        print(\"✅ Successfully found QAN data for both MySQL and PostgreSQL\")\n",
    "    elif 'mysql' in systems:\n",
    "        print(\"⚠️ Found QAN data for MySQL but not PostgreSQL\")\n",
    "    elif 'postgresql' in systems:\n",
    "        print(\"⚠️ Found QAN data for PostgreSQL but not MySQL\")\n",
    "    else:\n",
    "        print(\"❌ No QAN data found for either database system\")\n",
    "else:\n",
    "    print(\"Failed to query QAN data counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6b59f5",
   "metadata": {},
   "source": [
    "## Step 3: Check MySQL Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de452f05",
   "metadata": {},
   "source": [
    "# Query for MySQL test queries\n",
    "mysql_query = f\"\"\"\n",
    "SELECT\n",
    "  db.statement.sample AS query,\n",
    "  SUM(db.query.calls.delta) AS execution_count,\n",
    "  SUM(db.query.total_timer_wait.delta) / 1000000000 AS total_time_sec,\n",
    "  db.schema AS schema_name\n",
    "FROM qan_db\n",
    "WHERE \"__time\" BETWEEN TIMESTAMP '{start_time_str}' AND TIMESTAMP '{end_time_str}'\n",
    "  AND db.system = 'mysql'\n",
    "  AND db.statement.sample LIKE '%test_e2e%'\n",
    "GROUP BY db.statement.sample, db.schema\n",
    "ORDER BY total_time_sec DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "mysql_results = query_druid(mysql_query)\n",
    "if mysql_results:\n",
    "    df_mysql = pd.DataFrame(mysql_results)\n",
    "    print(\"MySQL Test Queries:\")\n",
    "    display(df_mysql)\n",
    "    \n",
    "    if not df_mysql.empty:\n",
    "        print(f\"✅ Successfully found integration test data in MySQL QAN records\")\n",
    "    else:\n",
    "        print(\"❌ No integration test data found in MySQL QAN records\")\n",
    "else:\n",
    "    print(\"Failed to query MySQL test data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ab52c0",
   "metadata": {},
   "source": [
    "## Step 4: Check PostgreSQL Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9d7a89",
   "metadata": {},
   "source": [
    "# Query PostgreSQL test queries\n",
    "pg_query = f\"\"\"\n",
    "SELECT\n",
    "  db.statement.sample AS query,\n",
    "  SUM(db.query.calls.delta) AS execution_count,\n",
    "  SUM(db.query.total_exec_time.delta) / 1000 AS total_time_sec\n",
    "FROM qan_db\n",
    "WHERE \"__time\" BETWEEN TIMESTAMP '{start_time_str}' AND TIMESTAMP '{end_time_str}'\n",
    "  AND db.system = 'postgresql'\n",
    "  AND db.statement.sample LIKE '%products%'\n",
    "GROUP BY db.statement.sample\n",
    "ORDER BY total_time_sec DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "pg_results = query_druid(pg_query)\n",
    "if pg_results:\n",
    "    df_pg = pd.DataFrame(pg_results)\n",
    "    print(\"PostgreSQL Test Queries:\")\n",
    "    display(df_pg)\n",
    "    \n",
    "    if not df_pg.empty:\n",
    "        print(f\"✅ Successfully found integration test data in PostgreSQL QAN records\")\n",
    "    else:\n",
    "        print(\"❌ No integration test data found in PostgreSQL QAN records\")\n",
    "else:\n",
    "    print(\"Failed to query PostgreSQL test data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e77c1a9",
   "metadata": {},
   "source": [
    "## Step 5: Query Execution Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a64318",
   "metadata": {},
   "source": [
    "# Query execution trends over time\n",
    "time_series_query = f\"\"\"\n",
    "SELECT\n",
    "  TIME_FLOOR(\"__time\", 'PT1M') AS time_bucket,\n",
    "  db.system AS database_system,\n",
    "  SUM(db.query.calls.delta) AS query_count\n",
    "FROM qan_db\n",
    "WHERE \"__time\" BETWEEN TIMESTAMP '{start_time_str}' AND TIMESTAMP '{end_time_str}'\n",
    "GROUP BY TIME_FLOOR(\"__time\", 'PT1M'), db.system\n",
    "ORDER BY time_bucket ASC\n",
    "\"\"\"\n",
    "\n",
    "time_series_results = query_druid(time_series_query)\n",
    "if time_series_results:\n",
    "    df_time = pd.DataFrame(time_series_results)\n",
    "    \n",
    "    if not df_time.empty:\n",
    "        # Convert timestamp to datetime for better plotting\n",
    "        df_time['time_bucket'] = pd.to_datetime(df_time['time_bucket'])\n",
    "        \n",
    "        # Plot time series\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        \n",
    "        # Plot each database system\n",
    "        for db_system in df_time['database_system'].unique():\n",
    "            db_data = df_time[df_time['database_system'] == db_system]\n",
    "            plt.plot(db_data['time_bucket'], db_data['query_count'], marker='o', linestyle='-', label=db_system)\n",
    "        \n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Query Execution Count')\n",
    "        plt.title('Query Execution Counts Over Time (1-minute intervals)')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"✅ Successfully generated time series visualization of query execution data\")\n",
    "    else:\n",
    "        print(\"❌ No time series data found\")\n",
    "else:\n",
    "    print(\"Failed to query time series data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8e8ded",
   "metadata": {},
   "source": [
    "## Step 6: Integration Test Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8a8c0c",
   "metadata": {},
   "source": [
    "# Let's create a summary of all our tests\n",
    "print(\"=== INTEGRATION TEST SUMMARY ===\")\n",
    "print(\"\")\n",
    "\n",
    "# 1. Druid Connection\n",
    "druid_ok = tables is not None\n",
    "print(f\"{'✅' if druid_ok else '❌'} Druid Connection\")\n",
    "\n",
    "# 2. QAN Data Available\n",
    "qan_data_ok = count_results is not None and not pd.DataFrame(count_results).empty\n",
    "print(f\"{'✅' if qan_data_ok else '❌'} QAN Data Available\")\n",
    "\n",
    "# 3. MySQL Test Data\n",
    "mysql_data_ok = mysql_results is not None and not pd.DataFrame(mysql_results).empty\n",
    "print(f\"{'✅' if mysql_data_ok else '❌'} MySQL Test Data\")\n",
    "\n",
    "# 4. PostgreSQL Test Data\n",
    "pg_data_ok = pg_results is not None and not pd.DataFrame(pg_results).empty\n",
    "print(f\"{'✅' if pg_data_ok else '❌'} PostgreSQL Test Data\")\n",
    "\n",
    "# 5. Time Series Data\n",
    "time_series_ok = time_series_results is not None and not pd.DataFrame(time_series_results).empty\n",
    "print(f\"{'✅' if time_series_ok else '❌'} Time Series Data\")\n",
    "\n",
    "print(\"\")\n",
    "overall_success = all([druid_ok, qan_data_ok, mysql_data_ok, pg_data_ok, time_series_ok])\n",
    "print(f\"{'✅' if overall_success else '❌'} OVERALL TEST STATUS: {'PASSED' if overall_success else 'FAILED'}\")\n",
    "\n",
    "if overall_success:\n",
    "    print(\"\")\n",
    "    print(\"Congratulations! The integration test has verified the full data flow:\")\n",
    "    print(\"1. Test data was generated in MySQL and PostgreSQL\")\n",
    "    print(\"2. Data was collected by OpenTelemetry QAN processors\")\n",
    "    print(\"3. Data was successfully ingested into Druid\")\n",
    "    print(\"4. JupyterLab successfully queried and visualized the data\")\n",
    "else:\n",
    "    print(\"\")\n",
    "    print(\"Some tests failed. Please check the individual test results above for details.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}